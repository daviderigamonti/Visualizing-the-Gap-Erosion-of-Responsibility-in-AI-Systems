@book{ALTAI,
author = {European Commission and Directorate-General for Communications Networks, Content and Technology},
title = {The Assessment List for Trustworthy Artificial Intelligence (ALTAI) for self assessment},
publisher = {Publications Office},
year = {2020},
doi = {doi/10.2759/002360}
}

@article{COEAIR,
	author = {Mark Coeckelbergh},
	pages = {2051--2068},
	title = {Artificial Intelligence, Responsibility Attribution, and a Relational Justification of Explainability},
	publisher = {Springer Verlag},
	journal = {Science and Engineering Ethics},
	year = {2020},
	doi = {10.1007/s11948-019-00146-8},
	number = {4},
	volume = {26}
}

@article{CONURI,
	doi = {10.1007/s10676-021-09616-9},
	publisher = {Springer Verlag},
	pages = {803--814},
	title = {Understanding Responsibility in Responsible Ai. Dianoetic Virtues and the Hard Problem of Context},
	journal = {Ethics and Information Technology},
	author = {Mihaela Constantinescu and Cristina Voinea and Radu Uszkai and Constantin Vic\ua},
	volume = {23},
	year = {2021},
	number = {4}
}

@Inbook{DURAPF,
	author="Durante, Massimo
	and Floridi, Luciano",
	editor="M{\"o}kander, Jakob
	and Ziosi, Marta",
	title="A Legal Principles-Based Framework for AI Liability Regulation",
	bookTitle="The 2021 Yearbook of the Digital Ethics Lab",
	year="2022",
	publisher="Springer International Publishing",
	address="Cham",
	pages="93--112",
	abstract="Europe has recently taken the path of regulating artificial intelligence (AI). This is a complex task, in which it is crucial to understand what the purposes of regulation are. In this perspective, it is not enough to identify and set ethical guidelines and legal norms. It is also important to envisage the legal principles that might steer the regulation of AI, which is aimed to reconcile technological innovation, economic development and user trust. Therefore, it may be useful to consider whether some principles may emerge from existing legislation in the AI sector. To this aim, we review the work of the Expert Group on Product Liability in the field of AI and Emerging Technologies (2019) as a case study. We show how their work has started to lay the basis for a set of legal principles for AI liability regime. An initial and open list of legal principles can serve as a benchmark for future work on a principles-based AI regulation.",
	isbn="978-3-031-09846-8",
	doi="10.1007/978-3-031-09846-8_7",
	url="https://doi.org/10.1007/978-3-031-09846-8_7"
}

@book{ETE,
	title = "Ethics, technology, and engineering : an introduction",
	abstract = "Featuring a wide range of international case studies, Ethics, Technology, and Engineering presents a unique and systematic approach for engineering students to deal with the ethical issues that are increasingly inherent in engineering practice.",
	author = "{Poel, van de}, I.R. and L.M.M. Royakkers",
	year = "2011",
	language = "English",
	isbn = "978-1-4443-3095-3",
	publisher = "Wiley-Blackwell",
	address = "United States",
}

@article{MATTRG,
	doi = {10.1007/s10676-004-3422-1},
	title = {The Responsibility Gap: Ascribing Responsibility for the Actions of Learning Automata},
	pages = {175--183},
	year = {2004},
	number = {3},
	publisher = {Kluwer Academic Publishers},
	journal = {Ethics and Information Technology},
	author = {Andreas Matthias},
	volume = {6}
}

@article{NISAIA,
	number = {1},
	publisher = {Springer},
	doi = {10.1007/bf02639315},
	volume = {2},
	author = {Helen Nissenbaum},
	pages = {25--42},
	journal = {Science and Engineering Ethics},
	year = {1996},
	title = {Accountability in a Computerized Society}
}

@article{NOVAIA,
	journal = {Ai and Society: Knowledge, Culture and Communication},
	title = {Accountability in Artificial Intelligence: What It is and How It Works},
	author = {Claudio Novelli and Mariarosaria Taddeo and Luciano Floridi},
	year = {forthcoming}
}

@incollection{OLJODA,
    author = {Olsen, Johan P.},
    isbn = {9780198800606},
    title = "{74Ambiguity and the Politics of Accountability}",
    booktitle = "{Democratic Accountability, Political Order, and Change: Exploring Accountability Processes in an Era of European Transformation}",
    publisher = {Oxford University Press},
    year = {2017},
    month = {04},
    abstract = "{In mainstream principal-agent approaches, as well as in much democratic theory and organization theory, accountability is linked to a belief in human agency and history determined by human will, causal understanding, and control. An institutional approach considers the possibility that events are not necessarily a product of the deliberate choices of identifiable actors, and takes into account that ambiguity, uncertainty, and limited control are inherent to political and organizational decision making. The fluidity and unresolved conflicts of political life make it difficult to conclude who is responsible and should be held to account and learn from experience and there is more to accountability processes than decision making, control, and compliance. Ambiguity and uncertainty about the past—what has happened, why, and who is responsible and should be held to account—open the way for the politics of accountability, involving sense-making processes, competing interpretations, and coping with conflict.}",
    doi = {10.1093/acprof:oso/9780198800606.003.0004},
    url = {https://doi.org/10.1093/acprof:oso/9780198800606.003.0004},
    eprint = {https://academic.oup.com/book/0/chapter/153440508/chapter-ag-pdf/44965507/book\_8053\_section\_153440508.ag.pdf},
}

@article{SANFRG,
	volume = {34},
	journal = {Philosophy and Technology},
	author = {Filippo Santoni de Sio and Giulio Mecacci},
	publisher = {Springer Verlag},
	number = {4},
	pages = {1057--1084},
	year = {2021},
	title = {Four Responsibility Gaps with Artificial Intelligence: Why They Matter and How to Address Them},
	doi = {10.1007/s13347-021-00450-x}
}

@article{SARER,
	pages = {1--10},
	title = {Engineering Responsibility},
	volume = {24},
	journal = {Ethics and Information Technology},
	publisher = {Springer Verlag},
	number = {3},
	year = {2022},
	doi = {10.1007/s10676-022-09660-z},
	author = {Nicholas Sars}
}

@article{SPAKR,
	doi = {10.1111/j.1468-5930.2007.00346.x},
	pages = {62--77},
	volume = {24},
	year = {2007},
	publisher = {Wiley-Blackwell},
	author = {Robert Sparrow},
	title = {Killer Robots},
	journal = {Journal of Applied Philosophy},
	number = {1}
}

@article{STARCA,
	doi = {10.1007/s10676-006-9112-4},
	volume = {8},
	title = {Responsible Computers? A Case for Ascribing Quasi-Responsibility to Computers Independent of Personhood or Agency},
	author = {Bernd Carsten Stahl},
	journal = {Ethics and Information Technology},
	pages = {205--213},
	number = {4},
	publisher = {Springer},
	year = {2006}
}

@article{VERAAC,
	doi = {10.1007/s11023-020-09532-9},
	year = {2020},
	volume = {31},
	author = {Ilse Verdiesen and Filippo Santoni de Sio and Virginia Dignum},
	pages = {137--163},
	publisher = {Springer Verlag},
	title = {Accountability and Control Over Autonomous Weapon Systems: A Framework for Comprehensive Human Oversight},
	journal = {Minds and Machines},
	number = {1}
}

@inbook{FEISC,
author = {Feinberg, Joel},
title = {Sua Culpa},
year = {1985},
isbn = {0534042570},
publisher = {Wadsworth Publ. Co.},
address = {USA},
booktitle = {Ethical Issues in the Use of Computers},
pages = {102–120},
numpages = {19}
}

@book{FISRAC,
	year = {1998},
	publisher = {New York: Cambridge University Press},
	editor = {Mark Ravizza},
	author = {John Martin Fischer and Mark Ravizza},
	title = {Responsibility and Control: A Theory of Moral Responsibility}
}


@article{POPOM,
title = "The problem of many hands : climate change as an example",
abstract = "In some situations in which undesirable collective effects occur, it is very hard, if not impossible, to hold any individual reasonably responsible. Such a situation may be referred to as the problem of many hands. In this paper we investigate how the problem of many hands can best be understood and why, and when, it exactly constitutes a problem. After analyzing climate change as an example, we propose to define the problem of many hands as the occurrence of a gap in the distribution of responsibility that may be considered morally problematic. Whether a gap is morally problematic, we suggest, depends on the reasons why responsibility is distributed. This, in turn, depends, at least in part, on the sense of responsibility employed, a main distinction being that between backward-looking and forward-looking responsibility.",
author = "{Poel, van de}, I.R. and J.N. Fahlquist and N. Doorn and S.D. Zwart and L.M.M. Royakkers",
year = "2012",
doi = "10.1007/s11948-011-9276-0",
language = "English",
volume = "18",
pages = "49--67",
journal = "Science and Engineering Ethics",
issn = "1353-3452",
publisher = "Springer",
number = "1",

}
