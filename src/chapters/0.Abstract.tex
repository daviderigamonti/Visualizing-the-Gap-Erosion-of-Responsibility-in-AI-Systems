\begin{abstract}
What is commonly referred as ``responsibility gap'', in the context of the philosophical debate regarding Artificial Intelligence (AI), is the impossibility to completely ascribing the responsibility for the actions of an autonomous learning system to its designer.
This issue is particularly relevant in modern society, where we are witnessing a significant increase in pervasiveness of such systems.
Furthermore, most of the examples presented in this paper will see autonomous learning systems applied to the military field, as it is a critical area where the employment of these systems may be a matter of life and death.
In this paper we will focus on the responsibility gap and the erosion of responsibility by analyzing relevant literature, comparing ideas and possibly formulating new perspectives.
Distinct emphasis will be put on the inadequacy of classical responsibility frameworks when applied to modern AI systems, as they tipically adopt a traditional functional perspective on engineering artifacts; this perspective contrasts with the opacity and behavioral unpredictability of learning automata.
In the paper we will also dwell on the potential consequences of the proposed problem and explore possible solutions, paying particular attention and formulating responses to some plausible opposing viewpoints. 
\end{abstract}