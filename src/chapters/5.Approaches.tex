\section{General Approaches}\label{sec:approaches}

% Introduction
This paper will try to lay out a comprehensive approach that highlights a series of general responsibility practices for learning autonomous systems.
This isn't meant to be a perfect or original solution to any of the problems that have been identified so far as our approach focuses on the analysis and comparison of pre-existing ideas.

% Sociotechnical considerations
Analyzing the consequences found in the previous section through a sociotechnical lens is fundamental for fully un\-der\-stand\-ing the whole extent of the matter at hand \parencite{THETE, NOVAIA}; realizing that companies, corporations and their profit-driven approach has become the main driving force of AI development in the past years is the starting point for making any meaningful change.
For a sociotechnical approach it is important to not only manufacture technical solutions, but also take into account the underlying social structure towards a joint optimization of the two components.
This is the main pitfall of the \textit{solutionism} approach, as it implies that a general and absolute solution to the problem can be achieved by just means of new legal or technical tools \parencite{MORTSE, STILML, SANFRG}.

% Fatalism and deflationism
Sio and Mecacci give an in-depth description of the main approaches to the central problem, together they identify the two main perspectives collocated at the two opposite extremes of the debate: \textit{fatalism} and \textit{deflationism}.
While fatalism looks at the responsibility gap as an unresolvable dilemma, seeing the development of learning systems and human moral responsibility in strict mutual exclusion \parencite{MATTRG}; deflationism takes the opposite stance and, while admitting that responsibility gaps exist, tries to depict their presence as an inevitable side effect that could be accepted and internalized by society since (as it happened with many technologies in the past) the benefits outweigh the drawbacks \parencite{HAYTMP, SIJWA}.

% Quasi-responsibility
Another compelling viewpoint is the \textit{quasi-responsibility} approach \parencite{STARCA}, which explores the idea of considering autonomous systems as pseudo-agents of responsibility; this solution stands out from the rest due to its radical approach, capable of solving the issue at its core.
However, it is only possible to reach this conclusion under the assumption that the solution does, in fact, exist; giving a set of artificial moral values to a machine is not an easy task for various reasons and even then, to human eyes it is not possible to hold an artifact blameworthy in the same way as a human might be, thus leaving a hypotetical victim without proper explanation and compensation.