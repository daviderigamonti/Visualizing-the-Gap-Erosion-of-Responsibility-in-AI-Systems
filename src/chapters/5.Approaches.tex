\section{General Approaches}\label{sec:approaches}

% Introduction
This paper will try to present a comprehensive approach that highlights a range of general responsibility practices for learning autonomous systems.
This isn't meant to be a flawless or groundbreaking solution to any of the problems that have been identified so far as our approach focuses on the analysis and comparison of pre-existing ideas.

% Sociotechnical considerations
Analyzing the consequences found in the previous section through a sociotechnical lens is fundamental for fully un\-der\-stand\-ing the whole extent of the matter at hand \parencite{THETE, NOVAIA}; realizing that companies, corporations and their profit-driven approach have become the main driving force of AI development in the past years is the starting point for making any meaningful change.
For a sociotechnical approach, it is important to not only manufacture technical solutions but also take into account the underlying social structure, aiming towards a joint optimization of the two components.
This represents the main pitfall of the \textit{solutionist} approach, as it implies that a general and absolute solution to the problem can be achieved solely through the implementation of new legal or technical tools \parencite{MORTSE, STILML, SANFRG}.

% Fatalism and deflationism
In their comprehensive analysis, Sio and Mecacci give an in-depth description of the main approaches to the central problem; together they identify the two main perspectives located at the two opposite extremes of the debate: \textit{fatalism} and \textit{deflationism}.
While fatalism looks at the responsibility gap as an unsolvable dilemma, seeing the development of learning systems and human moral responsibility in strict mutual exclusion \parencite{MATTRG}; deflationism takes the opposite stance and, while admitting that responsibility gaps exist, tries to portray their presence as an inevitable side effect that could be accepted and internalized by society since (as it happened with many technologies in the past) the benefits outweigh the drawbacks \parencite{HAYTMP, SIJWA}.

% Quasi-responsibility
Another compelling viewpoint is the \textit{quasi-responsibility} approach \parencite{STARCA}, which explores the idea of considering autonomous systems as pseudo-agents of responsibility; this solution distinguishes itself from other approaches due to its radical nature, capable of solving the issue at its core.
However, reaching this conclusion is only possible under the assumption that the solution does, in fact, exist; assigning artificial moral values to a machine is not an easy task for various reasons and even then, from a human perspective it is not possible to hold an artifact blameworthy in the same way as a human might be, thus leaving a hypothetical victim of the system's actions without proper explanation and compensation.