\section{Societal and Technological Consequences}\label{sec:consequences}

% Introduction to the consequences
In the previous section we have observed that applying traditional responsibility frameworks to AI systems may be an unwise decision, now we are going to explore the possible consequences of this choice.
With technologies that are constantly being improved upon and a society that seems to be lagging behind it's important to understand that some issues can't be left unattended.
The array of possible negative outcomes that may result from a mishandling of the core problem is wide as there are numerous different types of imbalances that could influence the consequences in different ways.

% Unattended responsibility gap
If we decide to neglect the responsibility gap, the first undesired outcome becomes apparent: companies would be incentivized to distance themselves from their responsibility roles, shifting them on end users instead, resulting in frequent overlap for the \textit{patient} and \textit{agent} figures.
As much as this solution is dubious but not completely erroneous from a moral responsibility perspective (assuming that the system provider takes enough care in making sure that the end user has a certain level of knowledge about the system which is, in itself, another crucial issue), this approach shows its true criticality when seen from a blameworthiness perspective.
In this scenario the underlying culpability gap \parencite{SANFRG} is even more apparent: the end user realistically doesn't possess the same amount of knowledge about the system as the engineer who designed it, consequently the end user is unfairly being asked to take the blame for the system's actions.

% Traditional responsibility framework
On the other hand, if an increasing number of authorities opts for enforcing a strictly traditional conception of responsibility for autonomous systems, we may observe the opposite effect: companies could lose interest in developing and utilizing new AI technologies, considering them too hazardous or outright unprofitable given their inherent unpredictability.
In this scenario, AI research would be confined to theoretical and controlled environments, thus limiting its real life applicability, impeding the process and depriving humanity of the benefits that could have been derived by the advancements in this field.
To this day, a lot of autonomous sytems have already been deployed and internalized by society as useful tools for the daily use, removing them would impact the livelihood of many people, thus generating an additional moral dilemma on top of the issues that have been mentioned previously.