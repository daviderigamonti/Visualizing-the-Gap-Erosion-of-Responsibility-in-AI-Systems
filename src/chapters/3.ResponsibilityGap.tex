\section{The Responsibility Gap}\label{sec:responsibilitygap}

% Introduction of the responsibility gap and learning automata description
In his seminal work, Andreas Matthias discusses the exisence of a \textit{responsibility gap} \parencite{MATTRG} in the process of ascribing responsibility to agents involved in the activity of creating and interacting with learning automata.
First and foremost, it is important to comprehend in which ways autonomous learning systems differ from traditional engineering artifacts.
In most instances, a learning automaton is able to produce outputs following a certain learned logic that wasn't directly coded by a programmer but has been ``learned'' by providing examples of expected behavior; this particular approach makes it possible to achieve outstanding feats but at the same time it may raise some concerns on the actual \textit{control} that any agent may have on the system.

% Comparison with traditional framework and problem of many hands
As we have discussed in the previous section, \textit{knowledge and control} of the agent over the system are fundamental preconditions for ascribing responsibility (and even more so accountability) in traditional frameworks.
However, when facing a system that has the properties of a \textit{black box}, we cannot assume that anyone would be able to know its inner workings, not even the creator of the automaton, let alone its potential users.
In addition, even the \textit{causality} conditions may not be satisfied if we consider what is known in the literature as the \textit{problem of many hands} \parencite{POPOM, COEAIR, NISAIA} and consists in the impossibility of generalizing the single agent responsibility to a collective entity, as an unfeasible unfolding of long and convoluted chains of events is needed to fully understand the contribution of each agent.
The problem of many hands is not restricted to the learning automata case, but it is certainly amplified by the fact that AI models are usually composed of many different modules (\textit{problem of many things}~\cite{COEAIR}) which are the product of contributions given by many different people with different skills, ideals and goals.

% Example
An interesting case of acknowledging the responsibility gap and creating moral grounds to face it can be seen in the domain of Lethal Autonomous Weapon Systems (LAWS).
In particular, the issue arises and shows its criticality due to the fact that systems in this domain are specifically designed to take human lives in an autonomous manner.
In an unfortunate scenario, it may be possible that innocent civilian lives could be lost due to a minor error.
When a human is directly employing a weapon, it is safe to assume that they bear the moral responsibility for any supposed error (assuming the weapon doesn't present any malfunction).
However, if the weapon is operating on its own, suddenly the lines blur and in the event of an unfortunate incident, the process of attributing responsibility is no longer clear.
To mitigate this problem, the International Committee of the Red Cross (ICRC) states that \textit{meaningful}, \textit{effective} or \textit{appropriate} human control over weapon systems is needed and should be maintained in order to properly ascribe responsibility \parencite{ICRCEA}.
Nevertheless, no proper definition for these terms is given and many scholars have focused on defining and operationalizing the notion of \textit{meaningful human control} in recent years \parencite{VERAAC, EKEMBS}.