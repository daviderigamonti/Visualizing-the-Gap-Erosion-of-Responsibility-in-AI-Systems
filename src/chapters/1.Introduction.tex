\section{Introduction}\label{sec:introduction}

The historical model for determining the responsibility of a company or an individual that develops an AI system isn't valid when looking at autonomous systems.
A new perspective is needed to effectively discern the full extent of human responsibility when a system is said to be able to ``act on its own''.

The main goal of this article is to underline the presence of a responsibility gap \parencite{MATTRG-3} when analyzing all kinds of autonomous systems (in particular those capable of ``learning''), and to provide possible approaches and solutions in order to tackle the problems that may arise from applying classical frameworks of responsibility in current and future contexts that employ AI technology.
The issue at the core of this paper has already been studied by many \todo{maybe citation}, offering different points of view and valuable insight, however, to this day there are still a lot of questions that remain unanswered.
This paper is not aiming to give definitive answers to the issue at hand, instead it will just focus on the presented thesis by providing argumentative evidence and relevant case-studies; to do so, in~\autoref{sec:a} it will start by giving semi-formal definitions of \textit{responsibility} (including some peculiar variations) and its applicability on non-autonomous systems following the classical framework, while is~\autoref{sec:b} devoted to presenting, assessing and analyzing the opposite situation, highlighting the flaws of the previous approach; \autoref{sec:c} will focus on the possible long and short term consequences of erroneous handling of the presented issues, while \autoref{sec:d} will offer some plausible solutions to mitigate and possibly prevent those consequences; to conclude, \autoref{sec:e} is dedicated to the acknowledgement of eventual points of objection and \autoref{sec:f} will wrap up the paper.\todo{insert refs}