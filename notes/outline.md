# Paper outline

## Brainstorm

- Accountability in Computer Science and Artificial Intelligence
- Responsibility vs Accountability vs Attributability vs Liability
- Malicious intent, ethics and social goals
- Sentience and effective control over an AI system
- Moral implications of creating a sentient systems will be overlooked
- Indirect responsibility

## Thesis

The **historical** model for determining the **responsibility** of a company/individual that creates an AI system **isn't valid** when looking at **autonomous systems**.
A new perspective is needed to effectively discern the full extent of human responsibility when a system is said to be able to "act on its own".

## Structure

0. Abstract
1. Introduction
    - Thesis
    - Motivating the thesis (why should the reader care?)
    - Technical terminology
        - Responsibility vs Accountability vs Attributability vs Liability
    - Overview of the paper
2. Classic definition of responsibility and its applicability on non-intelligent systems
    - Red herring of Aristotelian conditions of responsibility
3. Problems and fairness concerns of employing a classical responsibility framework in evaluating AI systems
    - Inherent opacity of autonomous systems
4. Consequences of mishandling or ignoring the raised concerns
    - Disincetivization of pursuing AI research
    - Unjust punishments and sanctions
5. Alternative solutions and approaches for tackling the issue at hand
    - Containing technology drive 
6. Possibile points of objection towards the claim or its presented solutions
7. Conclusion
8. Bibliography